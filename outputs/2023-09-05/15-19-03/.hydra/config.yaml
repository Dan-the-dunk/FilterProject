train_transform:
  _target_: albumentations.Compose
  keypoint_params:
    _target_: albumentations.KeypointParams
    format: xy
    remove_invisible: false
  transforms:
  - _target_: albumentations.Resize
    height: 256
    width: 256
    always_apply: true
  - _target_: albumentations.CenterCrop
    height: 224
    width: 224
    always_apply: true
  - _target_: albumentations.Normalize
    mean:
    - 0.485
    - 0.456
    - 0.406
    std:
    - 0.229
    - 0.224
    - 0.225
  - _target_: albumentations.pytorch.transforms.ToTensorV2
val_transform:
  _target_: albumentations.Compose
  keypoint_params:
    _target_: albumentations.KeypointParams
    format: xy
    remove_invisible: false
  transforms:
  - _target_: albumentations.Resize
    height: 256
    width: 256
    always_apply: true
  - _target_: albumentations.CenterCrop
    height: 224
    width: 224
    always_apply: true
  - _target_: albumentations.Normalize
    mean:
    - 0.485
    - 0.456
    - 0.406
    std:
    - 0.229
    - 0.224
    - 0.225
  - _target_: albumentations.pytorch.transforms.ToTensorV2
_target_: src.data.DlibModule.DlibModule
data_dir: ${paths.data_dir}
batch_size: 32
train_val_test_split:
- 792
- 72
- 114
num_workers: 0
pin_memory: false
